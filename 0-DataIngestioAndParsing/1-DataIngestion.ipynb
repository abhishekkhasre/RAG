{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9eeca9",
   "metadata": {},
   "source": [
    "### üéØ Module Overview\n",
    "This module covers everything you need to know about parsing and ingesting data for RAG systems, from basic text files to complex PDFs and databases. We'll use LangChain v0.3 and explore each technique with practical examples.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- Introduction to Data Ingestion\n",
    "- Text Files (.txt)\n",
    "- PDF Documents\n",
    "- Microsoft Word Documents\n",
    "- CSV and Excel Files\n",
    "- JSON and Structured Data\n",
    "- Web Scraping\n",
    "- Databases (SQL)\n",
    "- Audio and Video Transcripts\n",
    "- Advanced Techniques\n",
    "- Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcab9f",
   "metadata": {},
   "source": [
    "## Introduction to Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92366a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Dict,Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46a12a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetUp Completed\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "print(\"SetUp Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb7ea4",
   "metadata": {},
   "source": [
    "## Understanding Document Struture In LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4936b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Content : This is the main text that will embedded and searched\n",
      "MetaData : {'source': 'example.txt', 'page': 1, 'author': 'The Abishek Khasre', 'date_creatted': '2025-09-06', 'custom_feild': 'any value'}\n"
     ]
    }
   ],
   "source": [
    "## create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text that will embedded and searched\",\n",
    "    metadata={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"page\":1,\n",
    "        \"author\":\"The Abishek Khasre\",\n",
    "        \"date_creatted\":\"2025-09-06\",\n",
    "        \"custom_feild\" : \"any value\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Document Structure\")\n",
    "\n",
    "print(f\"Content : {doc.page_content}\")\n",
    "print(f\"MetaData : {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f248da",
   "metadata": {},
   "source": [
    "### TextLoader - Read Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d338aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30952d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n",
      "<class 'list'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(docs)\n",
    "print(type(docs))\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c55a4e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded 1 document\n",
      "Content preview: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for ...\n",
      "Metadata: {'source': './data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "documents=loader.load()\n",
    "print(f\"üìÑ Loaded {len(documents)} document\")\n",
    "print(f\"Content preview: {documents[0].page_content[:100]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a0334",
   "metadata": {},
   "source": [
    "## DirectoryLoader - Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa2bd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loaded 2 documents\n",
      "\n",
      "Document 1:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 575 characters\n",
      "\n",
      "Document 2:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 489 characters\n",
      "\n",
      "üìä DirectoryLoader Characteristics:\n",
      "‚úÖ Advantages:\n",
      "  - Loads multiple files at once\n",
      "  - Supports glob patterns\n",
      "  - Progress tracking\n",
      "  - Recursive directory scanning\n",
      "\n",
      "‚ùå Disadvantages:\n",
      "  - All files must be same type\n",
      "  - Limited error handling per file\n",
      "  - Can be memory intensive for large directories\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob=\"**/*.txt\" , ##pattern to match files\n",
    "    loader_cls=TextLoader, ##loader class to use\n",
    "    loader_kwargs={\"encoding\" : \"utf-8\"}\n",
    ")\n",
    "\n",
    "\n",
    "documents=dir_loader.load()\n",
    "\n",
    "print(f\"üìÅ Loaded {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
    "\n",
    "\n",
    "# üìä Analysis\n",
    "print(\"\\nüìä DirectoryLoader Characteristics:\")\n",
    "print(\"‚úÖ Advantages:\")\n",
    "print(\"  - Loads multiple files at once\")\n",
    "print(\"  - Supports glob patterns\")\n",
    "print(\"  - Progress tracking\")\n",
    "print(\"  - Recursive directory scanning\")\n",
    "\n",
    "print(\"\\n‚ùå Disadvantages:\")\n",
    "print(\"  - All files must be same type\")\n",
    "print(\"  - Limited error handling per file\")\n",
    "print(\"  - Can be memory intensive for large directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4fa93",
   "metadata": {},
   "source": [
    "### Text Splitting Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a99cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '), Document(metadata={'source': 'data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b12e2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Method 1-Charachter Text Splitter\n",
    "\n",
    "text = documents[0].page_content\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba18005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Character Text Splitter\n",
      "\n",
      "Document 1:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 121 characters\n",
      "\n",
      "Document 2:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 179 characters\n",
      "\n",
      "Document 3:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 177 characters\n",
      "\n",
      "Document 4:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 85 characters\n",
      "\n",
      "Document 5:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 130 characters\n",
      "\n",
      "Document 6:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 200 characters\n",
      "\n",
      "Document 7:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 154 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Character Text Splitter\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "splitted_docs = char_splitter.split_documents(documents)\n",
    "\n",
    "for i,doc in enumerate(splitted_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56c348ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Recursive Character Text Splitter\n",
      "\n",
      "Document 1:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 23 characters\n",
      "\n",
      "Document 2:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 193 characters\n",
      "\n",
      "Document 3:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 56 characters\n",
      "\n",
      "Document 4:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 138 characters\n",
      "\n",
      "Document 5:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 65 characters\n",
      "\n",
      "Document 6:\n",
      "  Source: data\\text_files\\machine_learning.txt\n",
      "  Length: 85 characters\n",
      "\n",
      "Document 7:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 31 characters\n",
      "\n",
      "Document 8:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 196 characters\n",
      "\n",
      "Document 9:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 35 characters\n",
      "\n",
      "Document 10:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 124 characters\n",
      "\n",
      "Document 11:\n",
      "  Source: data\\text_files\\python_intro.txt\n",
      "  Length: 96 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Recursive Character Text Splitter\")\n",
    "Recurchar_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\" , \"\\n\" ,\" \",\"\"],\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "splitted_docs = Recurchar_splitter.split_documents(documents)\n",
    "\n",
    "for i,doc in enumerate(splitted_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff344c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "----------\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "----------\n",
      "that can access data and use it to learn for themselves.\n",
      "----------\n",
      "Types of Machine Learning:\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "----------\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "----------\n",
      "Applications include image recognition, speech processing, and recommendation systems\n",
      "----------\n",
      "Python Programming Introduction\n",
      "----------\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
      "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
      "----------\n",
      "programming languages in the world.\n",
      "----------\n",
      "Key Features:\n",
      "- Easy to learn and use\n",
      "- Extensive standard library\n",
      "- Cross-platform compatibility\n",
      "- Strong community support\n",
      "----------\n",
      "Python is widely used in web development, data science, artificial intelligence, and automation.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for doc in splitted_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49a0dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text without natural break points\n",
    "simple_text = \"This is sentence one and it is quite long. This is sentence two and it is also quite long. This is sentence three which is even longer than the others. This is sentence four. This is sentence five. This is sentence six.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c211b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è3 TOKEN TEXT SPLITTER\n",
      "Created 3 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Token-based splitting\n",
    "print(\"\\n3 TOKEN TEXT SPLITTER\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,  # Size in tokens (not characters)\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks\")\n",
    "print(f\"First chunk: {token_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40bec1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Text Splitting Methods Comparison:\n",
      "\n",
      "CharacterTextSplitter:\n",
      "  ‚úÖ Simple and predictable\n",
      "  ‚úÖ Good for structured text\n",
      "  ‚ùå May break mid-sentence\n",
      "  Use when: Text has clear delimiters\n",
      "\n",
      "RecursiveCharacterTextSplitter:\n",
      "  ‚úÖ Respects text structure\n",
      "  ‚úÖ Tries multiple separators\n",
      "  ‚úÖ Best general-purpose splitter\n",
      "  ‚ùå Slightly more complex\n",
      "  Use when: Default choice for most texts\n",
      "\n",
      "TokenTextSplitter:\n",
      "  ‚úÖ Respects model token limits\n",
      "  ‚úÖ More accurate for embeddings\n",
      "  ‚ùå Slower than character-based\n",
      "  Use when: Working with token-limited models\n"
     ]
    }
   ],
   "source": [
    "# üìä Comparison\n",
    "print(\"\\nüìä Text Splitting Methods Comparison:\")\n",
    "print(\"\\nCharacterTextSplitter:\")\n",
    "print(\"  ‚úÖ Simple and predictable\")\n",
    "print(\"  ‚úÖ Good for structured text\")\n",
    "print(\"  ‚ùå May break mid-sentence\")\n",
    "print(\"  Use when: Text has clear delimiters\")\n",
    "\n",
    "print(\"\\nRecursiveCharacterTextSplitter:\")\n",
    "print(\"  ‚úÖ Respects text structure\")\n",
    "print(\"  ‚úÖ Tries multiple separators\")\n",
    "print(\"  ‚úÖ Best general-purpose splitter\")\n",
    "print(\"  ‚ùå Slightly more complex\")\n",
    "print(\"  Use when: Default choice for most texts\")\n",
    "\n",
    "print(\"\\nTokenTextSplitter:\")\n",
    "print(\"  ‚úÖ Respects model token limits\")\n",
    "print(\"  ‚úÖ More accurate for embeddings\")\n",
    "print(\"  ‚ùå Slower than character-based\")\n",
    "print(\"  Use when: Working with token-limited models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6beca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a18bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9ffe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801c52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab50565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f71ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb8526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d610bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4c5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42b6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
